import pandas as pd
import hashlib
import boto3
import io
import json

### Extraction from S3 ### 
def extract_data_from_s3(bucket_name, file_name):
    s3 = boto3.client("s3")
    obj = s3.get_object(Bucket=bucket_name, Key=file_name)
    data = obj['Body'].read().decode('utf-8')
    data_json = json.loads(data)
    df = pd.DataFrame(data_json)
    return df

bucket_name = "cis9440-hw-raw-data"
file_name = "pedestrian_count_data.json"

data_df = extract_data_from_s3(bucket_name, file_name)

### Transformation ###
def transform_data(data_df):
    data_df = convert_data_types(data_df)
    data_df = extract_and_format_dates(data_df)
    data_df = drop_columns(data_df)
    data_df.rename(columns={'weather_summary': 'weather'}, inplace=True)
    data_df = drop_duplicates(data_df)
    return data_df

def convert_data_types(data_df):
    data_df['pedestrians'] = pd.to_numeric(data_df['pedestrians'], errors='coerce')
    data_df['towards_manhattan'] = pd.to_numeric(data_df['towards_manhattan'], errors='coerce')
    data_df['towards_brooklyn'] = pd.to_numeric(data_df['towards_brooklyn'], errors='coerce')
    return data_df

def extract_and_format_dates(data_df):
    data_df['hour_beginning'] = pd.to_datetime(data_df['hour_beginning'])
    data_df['year'] = data_df['hour_beginning'].dt.year
    data_df['quarter'] = data_df['hour_beginning'].dt.quarter
    data_df['month'] = data_df['hour_beginning'].dt.month
    data_df['day'] = data_df['hour_beginning'].dt.day
    data_df['hour'] = data_df['hour_beginning'].dt.hour
    data_df['date'] = data_df['hour_beginning'].dt.strftime('%Y-%m-%d')
    return data_df

def drop_columns(data_df):
    data_df.drop(columns=['hour_beginning', 'location'], inplace=True)
    return data_df

def drop_duplicates(data_df):
    data_df_str = data_df.astype(str)
    data_df_str.drop_duplicates(inplace=True)
    data_df = data_df_str.astype(data_df.dtypes.to_dict())
    return data_df

transformed_data_df = transform_data(data_df)

def handle_missing_values(data_df):
    data_df.dropna(subset=['pedestrians', 'towards_manhattan', 'towards_brooklyn', 'weather', 'temperature', 'precipitation'], inplace=True)
    return data_df

transformed_data_df.replace('nan', pd.NA, inplace=True)
transformed_data_df = handle_missing_values(transformed_data_df)

def reorganize(data_df):
    new_order = ['date','year', 'quarter', 'month', 'day', 'hour', 'pedestrians', 'towards_manhattan', 'towards_brooklyn', 'weather', 'temperature', 'precipitation', 'events']
    data_df = data_df[new_order]
    return data_df

transformed_data_df = reorganize(transformed_data_df)

### Mapping by generating IDs ###
def generate_ids(data_df):
    data_df['time_id'] = data_df.groupby(['date', 'year', 'quarter', 'month', 'day', 'hour']).ngroup() + 1
    
    # Create unique ID mappings for weather dimension
    weather_unique = data_df[['weather', 'temperature', 'precipitation']].drop_duplicates().reset_index(drop=True)
    weather_unique['weather_id'] = range(1, len(weather_unique) + 1)
    data_df = data_df.merge(weather_unique, on=['weather', 'temperature', 'precipitation'], how='left')
    
    # Create unique ID mappings for event dimension
    event_unique = data_df[['events']].drop_duplicates().reset_index(drop=True)
    event_unique['event_id'] = range(1, len(event_unique) + 1)
    data_df = data_df.merge(event_unique, on=['events'], how='left')
    
    return data_df

transformed_data_df = generate_ids(transformed_data_df)

### Storage back into S3 ###
def save_to_s3(dataframe, bucket, key):
    csv_buffer = io.StringIO()
    dataframe.to_csv(csv_buffer, index=False)
    s3_resource = boto3.resource('s3')
    s3_resource.Object(bucket, key).put(Body=csv_buffer.getvalue())

bucket_name = "cis9440-hw-raw-data"

save_to_s3(transformed_data_df[['date', 'year', 'quarter', 'month', 'day', 'hour', 'time_id']], bucket_name, 'dim_time.csv')
save_to_s3(transformed_data_df[['weather', 'temperature', 'precipitation', 'weather_id']], bucket_name, 'dim_weather.csv')
save_to_s3(transformed_data_df[['events', 'event_id']], bucket_name, 'dim_event.csv')
save_to_s3(transformed_data_df[['pedestrians', 'towards_manhattan', 'towards_brooklyn', 'time_id', 'weather_id', 'event_id']], bucket_name, 'fact_pedestrian.csv')

print('Transformed data saved to different CSV files in S3 bucket:', bucket_name)
